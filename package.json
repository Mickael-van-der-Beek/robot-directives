{
  "name": "robot-directives",
  "description": "Parse robot directives within HTML meta and/or HTTP headers.",
  "version": "0.4.0",
  "license": "MIT",
  "author": "Steven Vachon <contact@svachon.com> (https://www.svachon.com/)",
  "main": "lib",
  "repository": "stevenvachon/robot-directives",
  "dependencies": {
    "deep-freeze-node": "^1.1.2",
    "isbot": "^2.0.3",
    "useragent": "^2.1.13"
  },
  "devDependencies": {
    "chai": "^4.0.2",
    "coveralls": "^2.13.1",
    "mocha": "^3.4.2",
    "nyc": "^11.0.2"
  },
  "engines": {
    "node": ">= 6"
  },
  "scripts": {
    "ci": "npm run test && nyc report --reporter=text-lcov | coveralls",
    "posttest": "nyc report --reporter=html",
    "test": "nyc --reporter=text-summary mocha test.js --reporter=spec --check-leaks --bail"
  },
  "files": [
    "lib"
  ],
  "keywords": [
    "crawlers",
    "header",
    "html",
    "http",
    "meta",
    "metadata",
    "nofollow",
    "noindex",
    "robots",
    "robots.txt",
    "seo",
    "spiders"
  ]
}
